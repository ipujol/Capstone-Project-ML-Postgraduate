{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T20:47:14.209822Z",
     "start_time": "2023-07-03T20:47:12.623219Z"
    },
    "id": "mEVxznqqxSdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernadavo/.virtualenvs/dev_new/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/fernadavo/.virtualenvs/dev_new/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Data in Validation, Control and Test Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T19:36:46.589130Z",
     "start_time": "2023-06-30T19:36:46.585862Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:24:49.573161Z",
     "start_time": "2023-07-01T12:24:45.744530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Include day of week?\n",
    "clean_data = clean_data[['station_id', 'precipitation', 'temperature_2m', 'altitude', 'capacity',\n",
    "                         'month', 'day', 'hour', 'CTX-1', 'CTX-2', 'CTX-3', 'CTX-4',\n",
    "                         'percentage_docks_available']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:24:58.582894Z",
     "start_time": "2023-07-01T12:24:49.575847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8249637\n",
      "Validation set size: 2749879\n",
      "Test set size: 2749879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' with your data\n",
    "# Splitting into features (X) and target variable (y)\n",
    "X = clean_data.drop('percentage_docks_available', axis=1)  # Replace 'target_variable' with your actual target column name\n",
    "y = clean_data['percentage_docks_available']\n",
    "\n",
    "# Splitting into training and validation sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Splitting training set into control and validation groups\n",
    "X_control, X_validation, y_control, y_validation = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Printing the sizes of each group\n",
    "print(\"Training set size:\", X_control.shape[0])\n",
    "print(\"Validation set size:\", X_validation.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform encodings on categorical columns\n",
    "#### Finally we will only encode the stations with a target encoding at the beginning of each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final no utilizé el one-hot-encoding en mes, dia y hora porque saldrían muchas columnas (se puede probar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:34:28.789278Z",
     "start_time": "2023-07-01T12:34:15.423809Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernadavo/.virtualenvs/dev_new/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "target_encoder = ce.TargetEncoder(cols=['station_id'])\n",
    "X_control['station_encoded'] = target_encoder.fit_transform(X_control['station_id'], y_control)\n",
    "\n",
    "encoding_station_dict = X_control.groupby(['station_id', 'station_encoded']).mean().reset_index()\\\n",
    "[['station_id', 'station_encoded']].set_index('station_id')['station_encoded'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:34:37.819022Z",
     "start_time": "2023-07-01T12:34:37.300263Z"
    }
   },
   "outputs": [],
   "source": [
    "X_control = X_control[['station_encoded', 'precipitation', 'temperature_2m', 'altitude', 'capacity',\n",
    "                         'month', 'day', 'hour', 'CTX-1', 'CTX-2', 'CTX-3', 'CTX-4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:34:41.512013Z",
     "start_time": "2023-07-01T12:34:40.415793Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernadavo/.virtualenvs/dev_new/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_validation['station_encoded'] = X_validation['station_id'].map(encoding_station_dict)\n",
    "\n",
    "X_validation = X_validation[['station_encoded', 'precipitation', 'temperature_2m', 'altitude', 'capacity',\n",
    "                         'month', 'day', 'hour', 'CTX-1', 'CTX-2', 'CTX-3', 'CTX-4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:34:45.930033Z",
     "start_time": "2023-07-01T12:34:45.177632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fernadavo/.virtualenvs/dev_new/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test['station_encoded'] = X_test['station_id'].map(encoding_station_dict)\n",
    "\n",
    "X_test = X_test[['station_encoded', 'precipitation', 'temperature_2m', 'altitude', 'capacity',\n",
    "                         'month', 'day', 'hour', 'CTX-1', 'CTX-2', 'CTX-3', 'CTX-4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First test of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:34:49.838541Z",
     "start_time": "2023-07-01T12:34:49.834955Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:34:59.494470Z",
     "start_time": "2023-07-01T12:34:54.964133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.012332807799691148\n",
      "Coefficients: [ 1.72431562e-01  1.46177174e-04  6.70957571e-04 -1.64641976e-06\n",
      "  3.94663844e-06  3.48944023e-04 -3.20393483e-05 -6.65418858e-05\n",
      "  8.37974270e-01  1.39457278e-02 -1.91691311e-04 -2.40596892e-02]\n",
      "Columns: Index(['station_encoded', 'precipitation', 'temperature_2m', 'altitude',\n",
      "       'capacity', 'month', 'day', 'hour', 'CTX-1', 'CTX-2', 'CTX-3', 'CTX-4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import category_encoders as ce\n",
    "\n",
    "# Create an instance of the LinearRegression model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "linear_reg.fit(X_control, y_control)\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Intercept:\", linear_reg.intercept_)\n",
    "print(\"Coefficients:\", linear_reg.coef_)\n",
    "print(\"Columns:\", X_control.columns)\n",
    "## El coeficiente de las precipitaciones es muy bajo, habrá que meter precipitación por hora\n",
    "## Pedir a ChatGPT fuente de datos históricos de precipitacion por hora en BCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:35:42.671041Z",
     "start_time": "2023-07-01T12:35:42.446420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.0211255157617479\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "linear_reg_pred = linear_reg.predict(X_validation)\n",
    "\n",
    "# Calculate the mean squared error (MSE) to evaluate the model's performance\n",
    "mse = mean_squared_error(y_validation, linear_reg_pred)\n",
    "print(\"Linear Regression MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:38:23.932580Z",
     "start_time": "2023-07-01T12:35:45.886332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.02024179391804964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "\n",
    "rf_model.fit(X_control.head(100000), y_control.head(100000))\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.predict(X_validation)\n",
    "\n",
    "# Evaluate the model's performance using mean squared error (MSE)\n",
    "rf_mse = mean_squared_error(y_validation, rf_predictions)\n",
    "print(\"Random Forest MSE:\", rf_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T12:38:23.949334Z",
     "start_time": "2023-07-01T12:38:23.937316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8249637"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 43 seconds 50K rows -> Complete dataset in ~34 minutes\n",
    "len(X_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T17:38:23.708377Z",
     "start_time": "2023-06-24T17:38:23.705460Z"
    }
   },
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-01T12:35:59.331Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Train the Support Vector Machines (SVM) model\n",
    "svm_model = SVR()\n",
    "svm_model.fit(X_control.head(10000), y_control.head(10000))\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_validation)\n",
    "\n",
    "# Evaluate the model's performance using mean squared error (MSE)\n",
    "svm_mse = mean_squared_error(y_validation, svm_predictions)\n",
    "print(\"Support Vector Machines (SVM) MSE:\", svm_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-01T12:35:59.507Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8 seconds 1K rows -> Complete dataset in ~5.4 hours (not manageble)\n",
    "len(X_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-01T12:36:02.233Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_control_scaled = scaler.fit_transform(X_control)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "# Create a sequential model\n",
    "NN = Sequential()\n",
    "\n",
    "# Add input layer and hidden layer\n",
    "NN.add(Dense(64, activation='relu', input_shape=(X_control_scaled.shape[1],)))\n",
    "\n",
    "# Add output layer\n",
    "NN.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "NN.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "# Train the model\n",
    "NN.fit(X_control_scaled, np.array(y_control), epochs=3, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "mse = NN.evaluate(X_validation_scaled, np.array(y_validation))\n",
    "print(\"Neural Network MSE:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T19:47:00.525174Z",
     "start_time": "2023-06-30T19:42:49.942724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestRegressor\n",
      "Cross-Validation Scores: [0.02137131 0.02185079 0.02146338]\n",
      "Mean MSE: 0.02156182496240534\n",
      "Standard Deviation of MSE: 0.00020775444261539666\n",
      "\n",
      "Model: LinearRegression\n",
      "Cross-Validation Scores: [0.02131222 0.02196865 0.02168128]\n",
      "Mean MSE: 0.021654050726479995\n",
      "Standard Deviation of MSE: 0.00026867663433255293\n",
      "\n",
      "Model: SVR\n",
      "Cross-Validation Scores: [0.0215479  0.02212105 0.02185163]\n",
      "Mean MSE: 0.021840196527920682\n",
      "Standard Deviation of MSE: 0.00023412651816526813\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "models = [\n",
    "    rf_model,\n",
    "    linear_reg,\n",
    "    svm_model,\n",
    "#     NN\n",
    "]\n",
    "\n",
    "# Perform cross-validation\n",
    "for model in models:\n",
    "    # Perform cross-validation on the model\n",
    "    scores = cross_val_score(model, X_control.head(100000), y_control.head(100000),\n",
    "                             cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert the negative MSE scores to positive\n",
    "    scores = -scores\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the scores\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    \n",
    "    # Print the model's performance metrics\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(\"Cross-Validation Scores:\", scores)\n",
    "    print(\"Mean MSE:\", mean_score)\n",
    "    print(\"Standard Deviation of MSE:\", std_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dC_K9wWJHDEo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
